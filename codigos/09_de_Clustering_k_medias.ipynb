{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "14925fb4",
      "metadata": {
        "id": "14925fb4"
      },
      "source": [
        "# Introducción al Clustering\n",
        "El clustering es una técnica de aprendizaje no supervisado que consiste en agrupar objetos similares en grupos o clusters. El objetivo principal de esta técnica es encontrar una estructura subyacente en un conjunto de datos y categorizarlos en grupos o clases basados en sus características. Algunas aplicaciones comunes de clustering incluyen segmentación de clientes, análisis de redes sociales, detección de anomalías y agrupamiento de documentos.\n",
        "\n",
        "Existen varios algoritmos de clustering, como K-means, DBSCAN, Clustering Jerárquico y Clustering Espectral. En este cuaderno nos enfocaremos en el algoritmo K-means.\n",
        "\n",
        "## Algoritmo K-means\n",
        "K-means es un algoritmo de clustering basado en particiones. Se trata de un algoritmo iterativo que intenta minimizar la suma de las distancias al cuadrado entre los puntos y el centroide de su respectivo cluster (inercia o varianza dentro del grupo). El algoritmo se ejecuta de la siguiente manera:\n",
        "\n",
        "1. Elegir el número de clusters, `k`.\n",
        "2. Asignar de manera aleatoria `k` puntos como centroides iniciales.\n",
        "3. Asignar cada punto al centroide más cercano.\n",
        "4. Actualizar los centroides calculando el promedio de todos los puntos asignados a cada centroide.\n",
        "5. Repetir los pasos 3 y 4 hasta que los centroides no cambien significativamente o se alcance un número máximo de iteraciones.\n",
        "\n",
        "La elección del número de clusters, `k`, es un aspecto crítico del algoritmo K-means. Un valor de `k` demasiado pequeño puede resultar en un agrupamiento deficiente, mientras que un valor demasiado grande puede resultar en un agrupamiento excesivamente detallado. Se pueden utilizar diversas técnicas para determinar el valor óptimo de `k`, como el método del codo o la silueta.\n",
        "\n",
        "A continuación, vamos a generar un conjunto de datos sintéticos y aplicar el algoritmo K-means utilizando la biblioteca `sklearn`. Después, visualizaremos los resultados con `plotly`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5e51a91",
      "metadata": {
        "id": "f5e51a91"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import make_blobs\n",
        "import plotly.express as px\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Crear un conjunto de datos sintéticos\n",
        "X, y_true = make_blobs(n_samples=1000,\n",
        "                        centers=4,\n",
        "                        cluster_std=0.2,\n",
        "                        random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8c130a0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-25T00:24:39.881169Z",
          "start_time": "2023-03-25T00:24:39.788203Z"
        },
        "id": "a8c130a0"
      },
      "outputs": [],
      "source": [
        "# Aplicar el algoritmo K-means\n",
        "k = 4\n",
        "kmeans = KMeans(n_clusters=k,\n",
        "                init='k-means++',\n",
        "                max_iter=300,\n",
        "                n_init=10,\n",
        "                random_state=0)\n",
        "y_kmeans = kmeans.fit_predict(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4962d5dc",
      "metadata": {
        "id": "4962d5dc"
      },
      "outputs": [],
      "source": [
        "# Visualizar los resultados con plotly\n",
        "df = pd.DataFrame(X, columns=['x', 'y'])\n",
        "df['cluster'] = y_kmeans\n",
        "df['cluster'] = y_kmeans.astype(str)\n",
        "\n",
        "fig = px.scatter(df, x='x', y='y', color='cluster',\n",
        "                 title='Resultado de K-means (k=4)',\n",
        "                 color_discrete_sequence=px.colors.qualitative.D3)\n",
        "\n",
        "# Añadir los centroides\n",
        "fig.add_scatter(x=kmeans.cluster_centers_[:, 0], y=kmeans.cluster_centers_[:, 1],\n",
        "                mode='markers', marker=dict(symbol='x', size=12, color='black'),\n",
        "                name='Centroides')\n",
        "\n",
        "# Ajustes del layout para mantener la misma escala y aumentar el tamaño\n",
        "fig.update_layout(\n",
        "    width=800,  # Ajusta la anchura de la figura\n",
        "    height=600,  # Ajusta la altura de la figura\n",
        "    xaxis=dict(scaleanchor=\"y\", scaleratio=1),\n",
        "    title=dict(x=0.5)  # Centra el título\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64bfe46a",
      "metadata": {
        "id": "64bfe46a"
      },
      "source": [
        "El código anterior crea un conjunto de datos sintéticos con 300 puntos y 4 clusters. Luego, aplicamos el algoritmo K-means utilizando `sklearn.cluster.KMeans`. Utilizamos el método 'k-means++' para inicializar los centroides, lo que ayuda a acelerar la convergencia y mejorar la calidad de la solución. Ejecutamos el algoritmo durante un máximo de 300 iteraciones y lo inicializamos 10 veces con diferentes centroides iniciales. Luego, visualizamos los resultados con `plotly`.\n",
        "\n",
        "En este ejemplo, el algoritmo K-means agrupó los puntos en 4 clusters, como se esperaba. Sin embargo, en casos reales, donde no conocemos la cantidad óptima de clusters, podemos utilizar algún método para determinar el valor óptimo de `k`.\n",
        "\n",
        "## Método del codo\n",
        "\n",
        "El método del codo es una técnica heurística para determinar el número óptimo de clusters (`k`) en un conjunto de datos cuando se utiliza el algoritmo K-means. La idea principal es ejecutar K-means con diferentes valores de `k` y calcular la inercia (también conocida como suma de las distancias al cuadrado entre los puntos y el centroide de su respectivo cluster) para cada valor de `k`. Luego, se grafica la inercia en función de `k`, y el punto en el que la curva comienza a disminuir más lentamente (similar a un \"codo\") se considera el valor óptimo de `k`. La inercia es una medida de la cohesión de los clusters, es decir, qué tan cerca están los puntos dentro de un cluster. Un valor de inercia más bajo indica que los puntos dentro de un cluster están más cerca entre sí."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d4f5487",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-25T00:34:13.693824Z",
          "start_time": "2023-03-25T00:34:13.178686Z"
        },
        "id": "9d4f5487"
      },
      "outputs": [],
      "source": [
        "inertias = []\n",
        "ks = range(1,11) #[1,2,3,4,5,6,7,8,9,10]\n",
        "for k in ks:\n",
        "    kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "    kmeans.fit(X)\n",
        "    inertias.append(kmeans.inertia_)\n",
        "\n",
        "# Visualizar el método del codo\n",
        "fig = px.line(x=ks, y=inertias, title='Método del codo',\n",
        "              labels={'x': 'Número de clusters (k)', 'y': 'Inercia'})\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebc015da",
      "metadata": {
        "id": "ebc015da"
      },
      "source": [
        "En el código anterior, calculamos la inercia para diferentes valores de `k` (desde 1 hasta 10) y visualizamos los resultados utilizando el método del codo. El punto en el que la curva de inercia comienza a disminuir más lentamente (similar a un \"codo\") se considera el valor óptimo de `k`. En este caso, el método del codo sugiere que `k=4` es un buen valor para nuestro conjunto de datos sintético.\n",
        "\n",
        "En pocas palabras, el algoritmo K-means es una técnica de clustering útil y fácil de implementar que puede utilizarse en diversas aplicaciones de ciencia de datos. Es importante tener en cuenta que este algoritmo es sensible a la inicialización de los centroides y al número de clusters, por lo que es recomendable utilizar métodos como 'k-means++' para la inicialización y técnicas como el método del codo para determinar el valor óptimo de `k`. También es importante mencionar que el algoritmo K-means asume que los clusters son esféricos y de tamaño similar, lo cual puede no ser siempre cierto en problemas del mundo real. En tales casos, otros algoritmos de clustering, como DBSCAN o Clustering Jerárquico, podrían ser más apropiados.\n",
        "\n",
        "Además, es fundamental tener en cuenta que el algoritmo K-means es sensible a la escala de las características. Por lo tanto, es recomendable estandarizar o normalizar los datos antes de aplicar el algoritmo, especialmente cuando las características tienen diferentes unidades de medida o rangos de valores.\n",
        "\n",
        "Un ejemplo de cómo normalizar los datos utilizando `StandardScaler` de `sklearn` se presenta a continuación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c590d3d1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-25T00:49:11.620050Z",
          "start_time": "2023-03-25T00:49:11.611064Z"
        },
        "id": "c590d3d1"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Crear datos de ejemplo\n",
        "data = np.array([[1, 2000], [2, 3000], [3, 4000], [4, 5000]])\n",
        "\n",
        "# Estandarizar los datos\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "print(\"Datos estandarizados:\")\n",
        "print(data_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "709b43ef",
      "metadata": {
        "id": "709b43ef"
      },
      "source": [
        "`StandardScaler` es una clase de la biblioteca `sklearn` que se utiliza para estandarizar las características de un conjunto de datos. La estandarización es un proceso de preprocesamiento de datos que transforma las características para que tengan una media de 0 y una desviación estándar de 1. Esto es útil en muchos algoritmos de aprendizaje automático, como K-means y otros algoritmos de clustering, ya que estos algoritmos son sensibles a la escala de las características.\n",
        "\n",
        "La fórmula de la estandarización para cada característica es:\n",
        "\n",
        "$$\n",
        "z = \\frac{x - \\mu}{\\sigma}\n",
        "$$\n",
        "\n",
        "donde:\n",
        "\n",
        "* $z$: valor estandarizado\n",
        "* $x$: valor original de la característica\n",
        "* $\\mu$: media de la característica en el conjunto de datos\n",
        "* $\\sigma$: desviación estándar de la característica en el conjunto de datos\n",
        "\n",
        "En el ejemplo anterior, primero creamos un conjunto de datos de ejemplo con dos características. Luego, inicializamos un objeto `StandardScaler` y lo ajustamos a los datos de ejemplo utilizando el método `fit_transform`. Esto calcula la media y la desviación estándar de cada característica en el conjunto de datos y aplica la estandarización a los datos de ejemplo. El resultado son los datos estandarizados, donde cada característica tiene una media de 0 y una desviación estándar de 1."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d71cffb5",
      "metadata": {
        "id": "d71cffb5"
      },
      "source": [
        "Al aplicar K-means a datos estandarizados, el algoritmo puede ser más efectivo en la identificación de clusters con formas y tamaños diferentes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d35fb50",
      "metadata": {
        "id": "7d35fb50"
      },
      "source": [
        "## Ejemplo\n",
        "\n",
        "A continuación, se presenta un ejemplo de cómo utilizar el algoritmo K-means en un conjunto de datos real: el conjunto de datos de Wine. Este conjunto de datos contiene las mediciones químicas de 178 muestras de vino producidas en Italia. Estas muestras pertenecen a tres diferentes cultivares. Las características medidas incluyen, entre otras, el alcohol, la intensidad del color y el nivel de proline, lo cual es crucial para determinar la calidad y las características del vino. Aunque las etiquetas de los cultivares están disponibles en este conjunto de datos, no las utilizaremos para el algoritmo K-means, ya que es un algoritmo de aprendizaje no supervisado.\n",
        "\n",
        "Este análisis ayudará a ilustrar cómo la estandarización de las características puede impactar los resultados del algoritmo K-means, especialmente cuando las características tienen diferentes escalas. Utilizaremos las características de alcohol, intensidad del color y proline, que varían ampliamente en magnitud y son significativas para diferenciar entre diferentes tipos de vino. La visualización en 3D de los clusters permitirá apreciar mejor cómo la estandarización influye en la agrupación de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "549f93a0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-03-25T00:49:14.397125Z",
          "start_time": "2023-03-25T00:49:14.272144Z"
        },
        "id": "549f93a0"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Cargar el conjunto de datos de Wine\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "features = data.feature_names\n",
        "\n",
        "# Seleccionar tres características importantes\n",
        "important_features = ['alcohol', 'color_intensity', 'proline']\n",
        "indices = [features.index(feature) for feature in important_features]\n",
        "X_selected = X[:, indices]\n",
        "\n",
        "# Datos no escalados\n",
        "kmeans_original = KMeans(n_clusters=3, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "y_kmeans_original = kmeans_original.fit_predict(X_selected)\n",
        "df_original = pd.DataFrame(X_selected, columns=important_features)\n",
        "df_original['cluster'] = y_kmeans_original.astype(str)  # Convertir a string para tratar como categórico\n",
        "\n",
        "# Estandarizar las características seleccionadas\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_selected)\n",
        "kmeans_scaled = KMeans(n_clusters=3, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "y_kmeans_scaled = kmeans_scaled.fit_predict(X_scaled)\n",
        "df_scaled = pd.DataFrame(X_scaled, columns=important_features)\n",
        "df_scaled['cluster'] = y_kmeans_scaled.astype(str)  # Convertir a string para tratar como categórico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ff032bd",
      "metadata": {
        "id": "3ff032bd"
      },
      "outputs": [],
      "source": [
        "# Crear subplots\n",
        "fig = make_subplots(rows=1, cols=2, subplot_titles=('K-means en datos originales', 'K-means en datos escalados'),\n",
        "                    specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]])\n",
        "\n",
        "# Paleta de colores categóricos\n",
        "colors = px.colors.qualitative.Plotly\n",
        "\n",
        "# Añadir gráficas de datos originales\n",
        "fig.add_trace(go.Scatter3d(x=df_original['alcohol'], y=df_original['color_intensity'], z=df_original['proline'],\n",
        "                           mode='markers', marker=dict(size=5, color=[colors[int(i)] for i in df_original['cluster']]),\n",
        "                           name='Clusters originales'), row=1, col=1)\n",
        "\n",
        "# Añadir gráficas de datos escalados\n",
        "fig.add_trace(go.Scatter3d(x=df_scaled['alcohol'], y=df_scaled['color_intensity'], z=df_scaled['proline'],\n",
        "                           mode='markers', marker=dict(size=5, color=[colors[int(i)] for i in df_scaled['cluster']]),\n",
        "                           name='Clusters escalados'), row=1, col=2)\n",
        "\n",
        "# Actualizar el layout para mejorar la visualización\n",
        "fig.update_layout(height=600, width=1200, showlegend=True)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02bf202f",
      "metadata": {
        "id": "02bf202f"
      },
      "source": [
        "En este ejemplo, después de cargar y seleccionar las características relevantes del conjunto de datos de Wine, aplicamos el algoritmo K-means con `k=3`, correspondiente al número de tipos de vinos en el conjunto. Utilizamos un gráfico 3D de Plotly para visualizar los resultados, donde cada punto representa una muestra de vino y los colores indican los clusters formados por K-means. Los centroides de los clusters están destacados como cruces negras.\n",
        "\n",
        "Es interesante observar cómo la estandarización de las características influye significativamente en la agrupación. Específicamente, la variable \"proline\", que típicamente tiene valores en el rango de miles, domina la medida de distancia en el algoritmo K-means cuando los datos no están estandarizados. Esto puede llevar a una agrupación ineficaz, ya que las diferencias en las escalas de las variables sesgan los resultados hacia las características de mayor magnitud. Al estandarizar los datos, cada característica contribuye equitativamente al análisis, permitiendo que K-means identifique patrones más sutiles y efectivos entre las muestras de vino.\n",
        "\n",
        "Este comportamiento subraya la utilidad de K-means para explorar y descubrir estructuras ocultas en conjuntos de datos sin etiquetas, demostrando la importancia de la preparación adecuada de los datos antes de aplicar técnicas de aprendizaje automático."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}