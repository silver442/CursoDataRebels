{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a la Regresión\n",
    "\n",
    "La regresión es una técnica de aprendizaje supervisado que se utiliza para predecir un valor continuo. A diferencia de la clasificación, donde la salida es una etiqueta categórica, en la regresión la salida es un valor numérico. Algunos ejemplos de problemas de regresión incluyen:\n",
    "\n",
    "- Predecir el precio de una vivienda.\n",
    "- Estimar la demanda de un producto.\n",
    "- Determinar la puntuación de un estudiante en un examen.\n",
    "\n",
    "### Evaluación de Modelos de Regresión\n",
    "\n",
    "Para evaluar el rendimiento de un modelo de regresión, utilizamos varias métricas, incluyendo:\n",
    "\n",
    "- **Error Cuadrático Medio (MSE):** Es la media de los cuadrados de los errores, es decir, la media de las diferencias cuadráticas entre los valores predichos y los valores reales.\n",
    "- **Raíz del Error Cuadrático Medio (RMSE):** Es la raíz cuadrada del MSE y proporciona una medida en las mismas unidades que la variable objetivo.\n",
    "- **Coeficiente de Determinación (R²):** Indica la proporción de la variabilidad en la variable objetivo que es explicada por las características del modelo. Un valor de R² cercano a 1 indica un buen ajuste del modelo.\n",
    "\n",
    "En esta libreta, exploraremos tres métodos clásicos de regresión: Regresión Lineal, Regresión Polinómica y Regresión Ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presentación del Dataset\n",
    "\n",
    "Utilizaremos el conjunto de datos **California Housing**. Este dataset contiene información sobre el precio de casas en diferentes zonas de California. A continuación se describen las variables del dataset:\n",
    "\n",
    "- **MedInc:** Ingreso medio en un bloque.\n",
    "- **HouseAge:** Edad media de las casas en un bloque.\n",
    "- **AveRooms:** Número promedio de habitaciones por hogar.\n",
    "- **AveBedrms:** Número promedio de dormitorios por hogar.\n",
    "- **Population:** Población del bloque.\n",
    "- **AveOccup:** Número promedio de ocupantes por hogar.\n",
    "- **Latitude:** Latitud de la ubicación del bloque.\n",
    "- **Longitude:** Longitud de la ubicación del bloque.\n",
    "- **MedHouseVal:** Valor medio de las casas en un bloque (variable objetivo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cargar el dataset de California Housing\n",
    "california = fetch_california_housing()\n",
    "df = pd.DataFrame(california.data, columns=california.feature_names)\n",
    "df['MedHouseVal'] = california.target\n",
    "\n",
    "# Mostrar las primeras filas del dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de Datos\n",
    "\n",
    "Antes de aplicar cualquier algoritmo de regresión, es crucial preparar adecuadamente los datos. Este proceso incluye inspección y limpieza de datos, codificación de variables categóricas, normalización y estandarización, y finalmente, la división de los datos en conjuntos de entrenamiento y prueba.\n",
    "\n",
    "## Inspección y Limpieza de Datos\n",
    "\n",
    "El primer paso es inspeccionar los datos para identificar cualquier valor faltante o anomalías que puedan afectar el rendimiento del modelo. En nuestro dataset de California Housing, es importante revisar si hay valores nulos y entender la distribución de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspeccionar el dataset\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Verificar valores nulos\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización y Estandarización\n",
    "\n",
    "La normalización y estandarización son técnicas para escalar los datos, lo cual puede mejorar el rendimiento de los modelos de regresión. \n",
    "\n",
    "- **Normalización:** Escala los valores de las características para que estén en un rango de 0 a 1.\n",
    "- **Estandarización:** Escala los valores de las características para que tengan media 0 y desviación estándar 1.\n",
    "\n",
    "Estandarizaremos todas las características, incluyendo latitud y longitud, para asegurar que todas las variables sean tratadas en la misma escala por los algoritmos de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separar las características y la variable objetivo\n",
    "X = df.drop('MedHouseVal', axis=1)\n",
    "y = df['MedHouseVal']\n",
    "\n",
    "# Estandarizar todas las características\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convertir el resultado a un DataFrame para facilitar su manipulación\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "X_scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División de los Datos\n",
    "\n",
    "Es fundamental dividir los datos en conjuntos de entrenamiento y prueba para evaluar adecuadamente el rendimiento del modelo. Usualmente se usa una proporción de 70-30 o 80-20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Visualizar la forma de los conjuntos de datos\n",
    "print(f'Tamaño del conjunto de entrenamiento: {X_train.shape[0]} muestras')\n",
    "print(f'Tamaño del conjunto de prueba: {X_test.shape[0]} muestras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Lineal\n",
    "\n",
    "La regresión lineal es uno de los métodos más simples y comunes para modelar la relación entre una variable dependiente y una o más variables independientes. La idea es encontrar una línea recta (o hiperplano en dimensiones superiores) que mejor ajuste los datos.\n",
    "\n",
    "## Parámetros del Modelo de Regresión Lineal en scikit-learn\n",
    "\n",
    "En scikit-learn, el modelo de regresión lineal se implementa en la clase `LinearRegression`. Algunos de los parámetros importantes incluyen:\n",
    "\n",
    "- `fit_intercept`: Indica si se debe calcular la intersección para este modelo. Si es False, la intersección no se calculará (por defecto es True).\n",
    "- `normalize`: Cuando es True, las variables se normalizarán antes de realizar la regresión (por defecto es False). Este parámetro se ha desaconsejado y se recomienda estandarizar las características antes de llamar al `fit`.\n",
    "\n",
    "## Cómo Funciona el Algoritmo\n",
    "\n",
    "La ecuación de la regresión lineal es:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n + \\epsilon\n",
    "$$\n",
    "\n",
    "donde:\n",
    "- $y$ es la variable dependiente.\n",
    "- $x_1, x_2, ..., x_n$ son las variables independientes.\n",
    "- $\\beta_0$ es la intersección.\n",
    "- $\\beta_1, \\beta_2, ..., \\beta_n$ son los coeficientes de las variables independientes.\n",
    "- $\\epsilon$ es el término de error.\n",
    "\n",
    "1. **Inicialización de Parámetros:**\n",
    "   El modelo comienza calculando los valores iniciales para los parámetros, incluyendo los coeficientes $\\beta_0, \\beta_1, ..., \\beta_n$. Si `fit_intercept` es True, el modelo también calculará la intersección $\\beta_0$.\n",
    "\n",
    "2. **Cálculo de la Función de Costo:**\n",
    "   La función de costo utilizada es el error cuadrático medio (MSE), que mide la media de los cuadrados de los errores (diferencias entre los valores predichos y los valores reales).\n",
    "\n",
    "3. **Ajuste del Modelo:**\n",
    "   El modelo ajusta los coeficientes $\\beta$ para minimizar la función de costo, utilizando el método de mínimos cuadrados ordinarios.\n",
    "\n",
    "4. **Predicción:**\n",
    "   Una vez ajustados los coeficientes, el modelo puede realizar predicciones calculando la ecuación de la regresión lineal para nuevos valores de $x$.\n",
    "\n",
    "### Implementación en scikit-learn\n",
    "\n",
    "A continuación, implementaremos la regresión lineal utilizando scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la clase LinearRegression de scikit-learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Crear el modelo de regresión lineal\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones con los datos de prueba\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Error Cuadrático Medio (MSE): {mse:.2f}\")\n",
    "print(f\"Raíz del Error Cuadrático Medio (RMSE): {rmse:.2f}\")\n",
    "print(f\"Coeficiente de Determinación (R²): {r2:.2f}\")\n",
    "\n",
    "# Visualización de las predicciones vs valores reales\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, edgecolor='k', alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=3)\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.title('Predicciones vs Valores Reales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del Modelo\n",
    "\n",
    "Para evaluar el rendimiento del modelo de regresión lineal, utilizamos las siguientes métricas:\n",
    "\n",
    "- **Error Cuadrático Medio (MSE):** Es la media de los cuadrados de los errores, es decir, la media de las diferencias cuadráticas entre los valores predichos y los valores reales.\n",
    "- **Raíz del Error Cuadrático Medio (RMSE):** Es la raíz cuadrada del MSE y proporciona una medida en las mismas unidades que la variable objetivo.\n",
    "- **Coeficiente de Determinación (R²):** Indica la proporción de la variabilidad en la variable objetivo que es explicada por las características del modelo. Un valor de R² cercano a 1 indica un buen ajuste del modelo.\n",
    "\n",
    "La visualización de las predicciones versus los valores reales nos ayuda a ver cómo se ajusta el modelo a los datos de prueba. Idealmente, los puntos deberían alinearse cerca de la línea de identidad (línea diagonal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Polinómica\n",
    "\n",
    "La regresión polinómica es una extensión de la regresión lineal que permite modelar la relación entre la variable dependiente y las variables independientes como un polinomio. Esto es útil cuando la relación entre las variables no es lineal.\n",
    "\n",
    "## Parámetros del Modelo de Regresión Polinómica en scikit-learn\n",
    "\n",
    "En scikit-learn, la regresión polinómica se implementa utilizando una combinación de `PolynomialFeatures` y `LinearRegression`. Algunos de los parámetros importantes incluyen:\n",
    "\n",
    "- `degree`: El grado del polinomio. Determina la complejidad del modelo.\n",
    "- `include_bias`: Si se debe incluir un término de sesgo (intersección) en el polinomio.\n",
    "\n",
    "## Cómo Funciona el Algoritmo\n",
    "\n",
    "La ecuación de la regresión polinómica es:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + ... + \\beta_n x^n + \\epsilon\n",
    "$$\n",
    "\n",
    "donde:\n",
    "- $y$ es la variable dependiente.\n",
    "- $x$ es la variable independiente.\n",
    "- $\\beta_0, \\beta_1, ..., \\beta_n$ son los coeficientes del polinomio.\n",
    "- $\\epsilon$ es el término de error.\n",
    "\n",
    "1. **Generación de Características Polinómicas:**\n",
    "   Se transforman las características originales en un conjunto de características polinómicas utilizando `PolynomialFeatures`. Por ejemplo, si el grado es 2, se generan las características $x$, $x^2$, $xy$, $y^2$, etc.\n",
    "\n",
    "2. **Ajuste del Modelo Lineal:**\n",
    "   Se ajusta un modelo de regresión lineal a las características polinómicas generadas.\n",
    "\n",
    "3. **Predicción:**\n",
    "   Una vez ajustado el modelo, se pueden realizar predicciones utilizando la ecuación del polinomio ajustado.\n",
    "\n",
    "### Implementación en scikit-learn\n",
    "\n",
    "A continuación, implementaremos la regresión polinómica utilizando scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las clases necesarias de scikit-learn\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Crear el modelo de regresión polinómica con grado 2\n",
    "poly_reg = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('lin_reg', LinearRegression())\n",
    "])\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "poly_reg.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones con los datos de prueba\n",
    "y_pred = poly_reg.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Error Cuadrático Medio (MSE): {mse:.2f}\")\n",
    "print(f\"Raíz del Error Cuadrático Medio (RMSE): {rmse:.2f}\")\n",
    "print(f\"Coeficiente de Determinación (R²): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización del modelo polinómico\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, edgecolor='k', alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=3)\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.title('Predicciones vs Valores Reales (Regresión Polinómica)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión con K-Nearest Neighbors (KNN)\n",
    "\n",
    "La regresión con K-Nearest Neighbors (KNN) es un método no paramétrico utilizado para predecir valores continuos. La idea básica es que el valor predicho de una muestra es la media (o mediana) de los valores de sus k vecinos más cercanos.\n",
    "\n",
    "## Parámetros del Modelo de Regresión KNN en scikit-learn\n",
    "\n",
    "En scikit-learn, el modelo de regresión KNN se implementa en la clase `KNeighborsRegressor`. Algunos de los parámetros importantes incluyen:\n",
    "\n",
    "- `n_neighbors`: Número de vecinos a utilizar para las predicciones. Es uno de los parámetros más importantes y puede afectar significativamente el rendimiento del modelo.\n",
    "- `weights`: Función de ponderación utilizada en la predicción. Puede ser 'uniform' (todos los vecinos tienen el mismo peso) o 'distance' (los vecinos más cercanos tienen mayor peso).\n",
    "- `algorithm`: Algoritmo utilizado para calcular los vecinos más cercanos. Puede ser 'auto', 'ball_tree', 'kd_tree', o 'brute'.\n",
    "- `leaf_size`: Tamaño de las hojas pasadas al árbol BallTree o KDTree. Afecta la velocidad de construcción y consulta, así como la memoria requerida para almacenar el árbol.\n",
    "\n",
    "## Cómo Funciona el Algoritmo\n",
    "\n",
    "1. **Identificación de Vecinos:**\n",
    "   Para una muestra de prueba, el algoritmo encuentra las k muestras de entrenamiento más cercanas en el espacio de características.\n",
    "\n",
    "2. **Predicción:**\n",
    "   La predicción se hace tomando la media (o mediana) de los valores de las k muestras más cercanas.\n",
    "\n",
    "### Implementación en scikit-learn\n",
    "\n",
    "A continuación, implementaremos la regresión KNN utilizando scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la clase KNeighborsRegressor de scikit-learn\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Crear el modelo de regresión KNN\n",
    "knn_reg = KNeighborsRegressor(n_neighbors=5, weights='distance', algorithm='auto')\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "knn_reg.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones con los datos de prueba\n",
    "y_pred = knn_reg.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Error Cuadrático Medio (MSE): {mse:.2f}\")\n",
    "print(f\"Raíz del Error Cuadrático Medio (RMSE): {rmse:.2f}\")\n",
    "print(f\"Coeficiente de Determinación (R²): {r2:.2f}\")\n",
    "\n",
    "# Visualización del modelo KNN\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, edgecolor='k', alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=3)\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.title('Predicciones vs Valores Reales (Regresión KNN)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal para Regresión\n",
    "\n",
    "Las redes neuronales pueden ser una herramienta poderosa para la regresión, especialmente cuando las relaciones entre las características y la variable objetivo son no lineales y complejas.\n",
    "\n",
    "## Instalación de TensorFlow\n",
    "\n",
    "Para implementar una red neuronal en Python, utilizaremos la biblioteca TensorFlow. Si no la tienes instalada, puedes instalarla usando el siguiente comando:\n",
    "\n",
    "```bash\n",
    "pip install tensorflow\n",
    "```\n",
    "\n",
    "## Parámetros del Modelo de Red Neuronal en Keras\n",
    "\n",
    "En Keras, se pueden ajustar varios parámetros para construir y entrenar una red neuronal:\n",
    "\n",
    "- `layers`: El número de capas ocultas y el número de neuronas en cada capa.\n",
    "- `activation`: La función de activación para cada capa (por ejemplo, 'relu', 'sigmoid', etc.).\n",
    "- `optimizer`: El algoritmo de optimización para actualizar los pesos (por ejemplo, 'adam', 'sgd', etc.).\n",
    "- `loss`: La función de pérdida que se minimizará durante el entrenamiento (para regresión, típicamente 'mean_squared_error').\n",
    "\n",
    "## Cómo Funciona una Red Neuronal\n",
    "\n",
    "1. **Capas y Neuronas:**\n",
    "   - Una red neuronal está compuesta por capas de neuronas. La primera capa es la capa de entrada, la última capa es la capa de salida, y las capas intermedias son las capas ocultas.\n",
    "   - Cada neurona en una capa está conectada a todas las neuronas de la siguiente capa a través de conexiones ponderadas.\n",
    "\n",
    "2. **Propagación Hacia Adelante:**\n",
    "   - En la propagación hacia adelante, los datos de entrada se multiplican por los pesos y se pasan a través de una función de activación para producir una salida. Esta salida se convierte en la entrada de la siguiente capa.\n",
    "\n",
    "3. **Función de Activación:**\n",
    "   - Las funciones de activación introducen no linealidad en el modelo, permitiendo que la red neuronal aprenda relaciones complejas. Algunas funciones comunes son `relu` (Rectified Linear Unit) y `sigmoid`.\n",
    "\n",
    "4. **Cálculo de la Pérdida:**\n",
    "   - La pérdida es una medida de cuán lejos están las predicciones del modelo de los valores reales. Para problemas de regresión, comúnmente se usa el error cuadrático medio (MSE).\n",
    "\n",
    "5. **Propagación Hacia Atrás (Backpropagation):**\n",
    "   - En la propagación hacia atrás, la pérdida se propaga hacia atrás a través de la red, y los pesos se actualizan utilizando un algoritmo de optimización como Adam o SGD (Stochastic Gradient Descent) para minimizar la pérdida.\n",
    "\n",
    "6. **Entrenamiento:**\n",
    "   - El proceso de entrenamiento implica repetir la propagación hacia adelante y hacia atrás para múltiples épocas, ajustando los pesos cada vez para mejorar las predicciones.\n",
    "\n",
    "### Implementación en Keras\n",
    "\n",
    "A continuación, implementaremos una red neuronal simple utilizando Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definir el modelo de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))  # Capa de entrada y primera capa oculta\n",
    "model.add(Dense(32, activation='relu'))  # Segunda capa oculta\n",
    "model.add(Dense(1))  # Capa de salida\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Realizar predicciones con los datos de prueba\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "# Evaluar el modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Error Cuadrático Medio (MSE): {mse:.2f}\")\n",
    "print(f\"Raíz del Error Cuadrático Medio (RMSE): {rmse:.2f}\")\n",
    "print(f\"Coeficiente de Determinación (R²): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización del modelo de Red Neuronal\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, edgecolor='k', alpha=0.7)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=3)\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.title('Predicciones vs Valores Reales (Red Neuronal)')\n",
    "plt.show()\n",
    "\n",
    "# Visualizar el historial de entrenamiento\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Pérdida de Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Pérdida de Validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.title('Historial de Entrenamiento y Validación')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "\n",
    "En esta libreta hemos explorado varios métodos de regresión para predecir el valor medio de las casas en California utilizando diferentes algoritmos de aprendizaje automático. A continuación, se resumen los puntos clave y conclusiones de cada uno de los métodos estudiados:\n",
    "\n",
    "## Regresión Lineal\n",
    "\n",
    "- **Descripción:** Es el modelo más simple y asume una relación lineal entre las características y la variable objetivo.\n",
    "- **Ventajas:** Fácil de interpretar y rápido de entrenar.\n",
    "- **Desventajas:** No captura relaciones no lineales complejas.\n",
    "- **Rendimiento:** Este modelo sirve como una línea base para comparar con otros métodos más complejos.\n",
    "\n",
    "## Regresión Polinómica\n",
    "\n",
    "- **Descripción:** Extiende la regresión lineal al incluir términos polinómicos para capturar relaciones no lineales.\n",
    "- **Ventajas:** Puede modelar relaciones no lineales entre características y la variable objetivo.\n",
    "- **Desventajas:** Puede sobreajustarse fácilmente si se utiliza un grado polinómico alto.\n",
    "- **Rendimiento:** Mejor que la regresión lineal para datos con relaciones no lineales, pero el rendimiento depende del grado del polinomio.\n",
    "\n",
    "## Regresión con K-Nearest Neighbors (KNN)\n",
    "\n",
    "- **Descripción:** Método no paramétrico que predice el valor de una muestra basándose en los valores de sus vecinos más cercanos.\n",
    "- **Ventajas:** Simple y fácil de entender, no requiere suposiciones sobre la forma de la relación entre características y la variable objetivo.\n",
    "- **Desventajas:** Puede ser computacionalmente costoso para grandes conjuntos de datos, y su rendimiento depende de la elección del parámetro k.\n",
    "- **Rendimiento:** Bueno para problemas donde las relaciones entre las características son locales y no globales.\n",
    "\n",
    "## Red Neuronal para Regresión\n",
    "\n",
    "- **Descripción:** Modelo de aprendizaje profundo capaz de capturar relaciones no lineales complejas entre las características y la variable objetivo.\n",
    "- **Ventajas:** Gran capacidad para modelar relaciones complejas y no lineales.\n",
    "- **Desventajas:** Requiere más datos y poder computacional para entrenar adecuadamente. Puede ser difícil de interpretar.\n",
    "- **Rendimiento:** Generalmente mejor que los métodos anteriores en capturar patrones complejos en los datos, pero su efectividad depende del diseño y entrenamiento de la red.\n",
    "\n",
    "## Evaluación y Comparación de Modelos\n",
    "\n",
    "Para cada uno de estos métodos, evaluamos el rendimiento utilizando métricas como el Error Cuadrático Medio (MSE), la Raíz del Error Cuadrático Medio (RMSE), y el Coeficiente de Determinación (R²). Estos modelos mostraron diferentes niveles de precisión y capacidad de generalización:\n",
    "\n",
    "- **Regresión Lineal:** Buen rendimiento inicial, pero limitado en capturar relaciones no lineales.\n",
    "- **Regresión Polinómica:** Mejor en capturar no linealidades, pero riesgo de sobreajuste.\n",
    "- **KNN:** Adecuado para relaciones locales, pero sensible a la elección de k y computacionalmente costoso para grandes datasets.\n",
    "- **Red Neuronal:** Alta capacidad de modelado, pero requiere ajuste cuidadoso de hiperparámetros y mayor poder computacional.\n",
    "\n",
    "## Conclusión Final\n",
    "\n",
    "La elección del modelo de regresión adecuado depende de la naturaleza de los datos y del problema específico. Modelos más complejos como las redes neuronales pueden ofrecer mejor rendimiento en problemas con relaciones no lineales complejas, pero también requieren más datos y poder computacional. Por otro lado, modelos más simples como la regresión lineal y polinómica pueden ser suficientes para problemas con relaciones lineales o ligeramente no lineales y son más fáciles de interpretar y entrenar.\n",
    "\n",
    "Es fundamental probar varios modelos y ajustar sus hiperparámetros para encontrar el mejor rendimiento posible en un conjunto de datos específico. La evaluación y comparación de modelos es una parte crucial del proceso de modelado en la ciencia de datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
